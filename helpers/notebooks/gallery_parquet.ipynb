{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895cb286",
   "metadata": {},
   "source": [
    "Show Parquet / Pyarrow API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068d525",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f46ec68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:31:23.734466Z",
     "start_time": "2021-06-15T11:31:23.726173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33mWARNING\u001b[0m: Logger already initialized: skipping\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import numpy as np\n",
    "\n",
    "import helpers.dbg as dbg\n",
    "\n",
    "dbg.init_logger(verbosity=logging.INFO)\n",
    "_LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215ff89e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:19:03.323062Z",
     "start_time": "2021-06-15T11:19:03.303632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-03    0     A    85    86\n",
      "2000-01-04    0     A    97    62\n",
      "2000-01-05    0     A    12    25\n"
     ]
    }
   ],
   "source": [
    "def get_df() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create pandas random data, like:\n",
    "    \n",
    "                idx instr  val1  val2\n",
    "    2000-01-01    0     A    99    30\n",
    "    2000-01-02    0     A    54    46\n",
    "    2000-01-03    0     A    85    86\n",
    "    \"\"\"\n",
    "    num_rows = 100\n",
    "    instruments = \"A B C D E\".split()\n",
    "    cols = \"id stock val1 val2\".split()\n",
    "    df_idx = pd.date_range(pd.Timestamp(\"2000-01-01\"), pd.Timestamp(\"2000-01-15\"), freq=\"1D\")\n",
    "    #print(df_idx)\n",
    "    random.seed(1000)\n",
    "\n",
    "    df = []\n",
    "    for idx, inst in enumerate(instruments):\n",
    "        df_tmp = pd.DataFrame({\"idx\": idx,\n",
    "                               \"instr\": inst,\n",
    "                               \"val1\": [random.randint(0, 100) for k in range(len(df_idx))],\n",
    "                               \"val2\": [random.randint(0, 100) for k in range(len(df_idx))],\n",
    "                              }, index=df_idx)\n",
    "        #print(df_tmp)\n",
    "        df.append(df_tmp)\n",
    "    df = pd.concat(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e8235d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:35:16.903580Z",
     "start_time": "2021-06-15T11:35:16.895316Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-42-7a84befc1958>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-7a84befc1958>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    txt += \"# df=\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def df_to_str(df: pd.DataFrame) -> str:\n",
    "    txt = \"\"\n",
    "    txt += \"# df=\\n%s\" % df.head(3)\n",
    "    txt += \"\\n# df.shape=\\n%s\" % str(df.shape)\n",
    "    txt += \"\\n# df.dtypes=\\n%s\" % str(df.dtypes)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc474b",
   "metadata": {},
   "source": [
    "# Save and load all data in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb399156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:25:27.514505Z",
     "start_time": "2021-06-15T11:25:27.496811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "            idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-03    0     A    85    86\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = get_df()\n",
    "#print(df.head())\n",
    "print(df_to_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940dc7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:25:34.893472Z",
     "start_time": "2021-06-15T11:25:34.886977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table=\n",
      "pyarrow.Table\n",
      "idx: int64\n",
      "instr: string\n",
      "val1: int64\n",
      "val2: int64\n",
      "__index_level_0__: timestamp[ns]\n"
     ]
    }
   ],
   "source": [
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "print(\"table=\\n%s\" % table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93df67fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:25:38.560269Z",
     "start_time": "2021-06-15T11:25:38.533905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save.\n",
    "file_name = \"df_in_one_file.pq\"\n",
    "pq.write_table(table, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "155e36c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:25:51.016044Z",
     "start_time": "2021-06-15T11:25:51.001034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "idx: int64\n",
      "instr: string\n",
      "val1: int64\n",
      "val2: int64\n",
      "__index_level_0__: timestamp[us]\n",
      "# df=\n",
      "            idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-03    0     A    85    86\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load.\n",
    "df2 = pq.read_table(file_name)\n",
    "print(df2)\n",
    "\n",
    "df2 = df2.to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098757c",
   "metadata": {},
   "source": [
    "## Read a subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f4a652f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:27:11.924350Z",
     "start_time": "2021-06-15T11:27:11.910680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "idx: int64\n",
      "val1: int64\n",
      "# df=\n",
      "   idx  val1\n",
      "0    0    99\n",
      "1    0    54\n",
      "2    0    85\n",
      "# df.shape=\n",
      "(75, 2)\n",
      "# df.dtypes=\n",
      "idx     int64\n",
      "val1    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df2 = pq.read_table(file_name, columns=[\"idx\", \"val1\"])\n",
    "print(df2)\n",
    "\n",
    "df2 = df2.to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012cebdb",
   "metadata": {},
   "source": [
    "## Partitioned dataset\n",
    "\n",
    "from https://arrow.apache.org/docs/python/dataset.html#reading-partitioned-data\n",
    "\n",
    "- A dataset can exploit a nested structure, where the sub-dir names hold information about which subset of the data is stored in that dir\n",
    "- E.g., \"Hive\" patitioning scheme \"key=vale\" dir names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca26642e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:30:11.964993Z",
     "start_time": "2021-06-15T11:30:11.947282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "            idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-03    0     A    85    86\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = get_df()\n",
    "print(df_to_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cae349f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:30:27.617064Z",
     "start_time": "2021-06-15T11:30:27.541418Z"
    }
   },
   "outputs": [],
   "source": [
    "base = \".\"\n",
    "dir_name =  os.path.join(base, \"parquet_dataset_partitioned\")\n",
    "os.system(\"rm -rf %s\" % dir_name)\n",
    "\n",
    "pq.write_to_dataset(table,\n",
    "                    dir_name,\n",
    "                    partition_cols=['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd57116d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:30:30.672054Z",
     "start_time": "2021-06-15T11:30:30.389512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'idx=0'  'idx=1'  'idx=2'  'idx=3'  'idx=4'\r\n"
     ]
    }
   ],
   "source": [
    "!ls parquet_dataset_partitioned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac82b5ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:31:29.322947Z",
     "start_time": "2021-06-15T11:31:29.298883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./parquet_dataset_partitioned/idx=0/cab9de6eff0c47bcb688a1ce437c7f89.parquet\n",
      "./parquet_dataset_partitioned/idx=1/56813e569097420cae892720d3bb0789.parquet\n",
      "./parquet_dataset_partitioned/idx=2/5c9a17d2e1294dd58c7d8695868c2cb5.parquet\n",
      "./parquet_dataset_partitioned/idx=3/b28576eb22d54999980a313a24511497.parquet\n",
      "./parquet_dataset_partitioned/idx=4/8ee3f0d7585b48959a560c954562add8.parquet\n"
     ]
    }
   ],
   "source": [
    "# Read data back.\n",
    "dataset = ds.dataset(dir_name,\n",
    "                     format=\"parquet\",\n",
    "                     partitioning=\"hive\")\n",
    "\n",
    "print(\"\\n\".join(dataset.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64394b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:32:01.839074Z",
     "start_time": "2021-06-15T11:32:01.822727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "           instr  val1  val2  idx\n",
      "2000-01-01     A    99    30    0\n",
      "2000-01-02     A    54    46    0\n",
      "2000-01-03     A    85    86    0\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read everything.\n",
    "df2 = dataset.to_table().to_pandas()\n",
    "\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df96e1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:33:05.171630Z",
     "start_time": "2021-06-15T11:33:05.147040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "           instr  val1  val2  idx\n",
      "2000-01-01     B    18    22    1\n",
      "2000-01-02     B    59    89    1\n",
      "2000-01-03     B    91    90    1\n",
      "# df.shape=\n",
      "(15, 4)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "dtype: object\n",
      "# df=\n",
      "           instr  val1  val2  idx\n",
      "2000-01-01     A    99    30    0\n",
      "2000-01-02     A    54    46    0\n",
      "2000-01-03     A    85    86    0\n",
      "# df.shape=\n",
      "(45, 4)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load part of the data.\n",
    "\n",
    "df2 = dataset.to_table(filter=ds.field(\"idx\") == 1).to_pandas()\n",
    "print(df_to_str(df2))\n",
    "\n",
    "df2 = dataset.to_table(filter=ds.field(\"idx\") < 3).to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c27848",
   "metadata": {},
   "source": [
    "## Add year-month partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69d2ea15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:36:11.106142Z",
     "start_time": "2021-06-15T11:36:11.087701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "            idx instr  val1  val2  year  month\n",
      "2000-01-01    0     A    99    30  2000      1\n",
      "2000-01-02    0     A    54    46  2000      1\n",
      "2000-01-03    0     A    85    86  2000      1\n",
      "# df.shape=\n",
      "(75, 6)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "year      int64\n",
      "month     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = get_df()\n",
    "df[\"year\"] = df.index.year\n",
    "df[\"month\"] = df.index.month\n",
    "\n",
    "print(df_to_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a2f8c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:37:01.738085Z",
     "start_time": "2021-06-15T11:37:01.730748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table=\n",
      "pyarrow.Table\n",
      "idx: int64\n",
      "instr: string\n",
      "val1: int64\n",
      "val2: int64\n",
      "year: int64\n",
      "month: int64\n",
      "__index_level_0__: timestamp[ns]\n"
     ]
    }
   ],
   "source": [
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "print(\"table=\\n%s\" % table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9112ed65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:37:04.832037Z",
     "start_time": "2021-06-15T11:37:04.702121Z"
    }
   },
   "outputs": [],
   "source": [
    "base = \".\"\n",
    "dir_name =  os.path.join(base, \"pq_partitioned2\")\n",
    "os.system(\"rm -rf %s\" % dir_name)\n",
    "\n",
    "pq.write_to_dataset(table,\n",
    "                    dir_name,\n",
    "                    partition_cols=['idx', \"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "844913cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:37:17.553902Z",
     "start_time": "2021-06-15T11:37:17.276875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'idx=0'  'idx=1'  'idx=2'  'idx=3'  'idx=4'\r\n"
     ]
    }
   ],
   "source": [
    "!ls $dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5ba8be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:37:07.695235Z",
     "start_time": "2021-06-15T11:37:07.433612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc6b2314c7f640a38c62029280f6f65e.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls $dir_name/idx=0/year=2000/month=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d93f116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:37:26.153218Z",
     "start_time": "2021-06-15T11:37:26.109040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pq_partitioned2/idx=0/year=2000/month=1/bc6b2314c7f640a38c62029280f6f65e.parquet\n",
      "./pq_partitioned2/idx=1/year=2000/month=1/bb178ff0bdd344ca8328f9d67398b322.parquet\n",
      "./pq_partitioned2/idx=2/year=2000/month=1/16081eea25fd4da6bd802037b541766c.parquet\n",
      "./pq_partitioned2/idx=3/year=2000/month=1/1557b3c461054eadba16e3072fbd3a8a.parquet\n",
      "./pq_partitioned2/idx=4/year=2000/month=1/07a0c7fcf054450296b35452b57236ef.parquet\n"
     ]
    }
   ],
   "source": [
    "# Read data back.\n",
    "dataset = ds.dataset(dir_name,\n",
    "                     format=\"parquet\",\n",
    "                     partitioning=\"hive\")\n",
    "\n",
    "print(\"\\n\".join(dataset.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21148afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T11:39:19.396955Z",
     "start_time": "2021-06-15T11:39:19.374534Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "           instr  val1  val2  idx  year  month\n",
      "2000-01-01     C    99    37    2  2000      1\n",
      "2000-01-02     C    98    48    2  2000      1\n",
      "2000-01-03     C    70    58    2  2000      1\n",
      "# df.shape=\n",
      "(15, 6)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "year      int32\n",
      "month     int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read data back.\n",
    "dataset = ds.dataset(dir_name,\n",
    "                     format=\"parquet\",\n",
    "                     partitioning=\"hive\")\n",
    "\n",
    "df2 = dataset.to_table(filter=ds.field('idx') == 2).to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9e4e596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:09:20.925997Z",
     "start_time": "2021-06-15T00:09:20.720187Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1             idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-01    1     B    18    22\n",
      "2000-01-01    2     C    99    37\n",
      "2000-01-01    3     D     9    97\n",
      "2000-01-01    4     E    41    38\n",
      "1 0             idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "1 1             idx instr  val1  val2\n",
      "2000-01-01    1     B    18    22\n",
      "1 2             idx instr  val1  val2\n",
      "2000-01-01    2     C    99    37\n",
      "1 3             idx instr  val1  val2\n",
      "2000-01-01    3     D     9    97\n",
      "1 4             idx instr  val1  val2\n",
      "2000-01-01    4     E    41    38\n",
      "2             idx instr  val1  val2\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-02    1     B    59    89\n",
      "2000-01-02    2     C    98    48\n",
      "2000-01-02    3     D    29    97\n",
      "2000-01-02    4     E     0     6\n",
      "2 0             idx instr  val1  val2\n",
      "2000-01-02    0     A    54    46\n",
      "2 1             idx instr  val1  val2\n",
      "2000-01-02    1     B    59    89\n",
      "2 2             idx instr  val1  val2\n",
      "2000-01-02    2     C    98    48\n",
      "2 3             idx instr  val1  val2\n",
      "2000-01-02    3     D    29    97\n",
      "2 4             idx instr  val1  val2\n",
      "2000-01-02    4     E     0     6\n",
      "3             idx instr  val1  val2\n",
      "2000-01-03    0     A    85    86\n",
      "2000-01-03    1     B    91    90\n",
      "2000-01-03    2     C    70    58\n",
      "2000-01-03    3     D    37    88\n",
      "2000-01-03    4     E    71     5\n",
      "3 0             idx instr  val1  val2\n",
      "2000-01-03    0     A    85    86\n",
      "3 1             idx instr  val1  val2\n",
      "2000-01-03    1     B    91    90\n",
      "3 2             idx instr  val1  val2\n",
      "2000-01-03    2     C    70    58\n",
      "3 3             idx instr  val1  val2\n",
      "2000-01-03    3     D    37    88\n",
      "3 4             idx instr  val1  val2\n",
      "2000-01-03    4     E    71     5\n",
      "4             idx instr  val1  val2\n",
      "2000-01-04    0     A    97    62\n",
      "2000-01-04    1     B    90    13\n",
      "2000-01-04    2     C    15    46\n",
      "2000-01-04    3     D     3    61\n",
      "2000-01-04    4     E    75    25\n",
      "4 0             idx instr  val1  val2\n",
      "2000-01-04    0     A    97    62\n",
      "4 1             idx instr  val1  val2\n",
      "2000-01-04    1     B    90    13\n",
      "4 2             idx instr  val1  val2\n",
      "2000-01-04    2     C    15    46\n",
      "4 3             idx instr  val1  val2\n",
      "2000-01-04    3     D     3    61\n",
      "4 4             idx instr  val1  val2\n",
      "2000-01-04    4     E    75    25\n",
      "5             idx instr  val1  val2\n",
      "2000-01-05    0     A    12    25\n",
      "2000-01-05    1     B    53    32\n",
      "2000-01-05    2     C    24    62\n",
      "2000-01-05    3     D    47    87\n",
      "2000-01-05    4     E    90    25\n",
      "5 0             idx instr  val1  val2\n",
      "2000-01-05    0     A    12    25\n",
      "5 1             idx instr  val1  val2\n",
      "2000-01-05    1     B    53    32\n",
      "5 2             idx instr  val1  val2\n",
      "2000-01-05    2     C    24    62\n",
      "5 3             idx instr  val1  val2\n",
      "2000-01-05    3     D    47    87\n",
      "5 4             idx instr  val1  val2\n",
      "2000-01-05    4     E    90    25\n",
      "6             idx instr  val1  val2\n",
      "2000-01-06    0     A    50    87\n",
      "2000-01-06    1     B    88    20\n",
      "2000-01-06    2     C    37    76\n",
      "2000-01-06    3     D    16    25\n",
      "2000-01-06    4     E    21    13\n",
      "6 0             idx instr  val1  val2\n",
      "2000-01-06    0     A    50    87\n",
      "6 1             idx instr  val1  val2\n",
      "2000-01-06    1     B    88    20\n",
      "6 2             idx instr  val1  val2\n",
      "2000-01-06    2     C    37    76\n",
      "6 3             idx instr  val1  val2\n",
      "2000-01-06    3     D    16    25\n",
      "6 4             idx instr  val1  val2\n",
      "2000-01-06    4     E    21    13\n",
      "7             idx instr  val1  val2\n",
      "2000-01-07    0     A    45    85\n",
      "2000-01-07    1     B    25    36\n",
      "2000-01-07    2     C    48    35\n",
      "2000-01-07    3     D    26    51\n",
      "2000-01-07    4     E    12    43\n",
      "7 0             idx instr  val1  val2\n",
      "2000-01-07    0     A    45    85\n",
      "7 1             idx instr  val1  val2\n",
      "2000-01-07    1     B    25    36\n",
      "7 2             idx instr  val1  val2\n",
      "2000-01-07    2     C    48    35\n",
      "7 3             idx instr  val1  val2\n",
      "2000-01-07    3     D    26    51\n",
      "7 4             idx instr  val1  val2\n",
      "2000-01-07    4     E    12    43\n",
      "8             idx instr  val1  val2\n",
      "2000-01-08    0     A     8    46\n",
      "2000-01-08    1     B     2    11\n",
      "2000-01-08    2     C    40    60\n",
      "2000-01-08    3     D    17    96\n",
      "2000-01-08    4     E    62    25\n",
      "8 0             idx instr  val1  val2\n",
      "2000-01-08    0     A     8    46\n",
      "8 1             idx instr  val1  val2\n",
      "2000-01-08    1     B     2    11\n",
      "8 2             idx instr  val1  val2\n",
      "2000-01-08    2     C    40    60\n",
      "8 3             idx instr  val1  val2\n",
      "2000-01-08    3     D    17    96\n",
      "8 4             idx instr  val1  val2\n",
      "2000-01-08    4     E    62    25\n",
      "9             idx instr  val1  val2\n",
      "2000-01-09    0     A    59    29\n",
      "2000-01-09    1     B    97     0\n",
      "2000-01-09    2     C    84    42\n",
      "2000-01-09    3     D    80     9\n",
      "2000-01-09    4     E    52    18\n",
      "9 0             idx instr  val1  val2\n",
      "2000-01-09    0     A    59    29\n",
      "9 1             idx instr  val1  val2\n",
      "2000-01-09    1     B    97     0\n",
      "9 2             idx instr  val1  val2\n",
      "2000-01-09    2     C    84    42\n",
      "9 3             idx instr  val1  val2\n",
      "2000-01-09    3     D    80     9\n",
      "9 4             idx instr  val1  val2\n",
      "2000-01-09    4     E    52    18\n",
      "10             idx instr  val1  val2\n",
      "2000-01-10    0     A    21    58\n",
      "2000-01-10    1     B    68    40\n",
      "2000-01-10    2     C    29     1\n",
      "2000-01-10    3     D    95    28\n",
      "2000-01-10    4     E    78    12\n",
      "10 0             idx instr  val1  val2\n",
      "2000-01-10    0     A    21    58\n",
      "10 1             idx instr  val1  val2\n",
      "2000-01-10    1     B    68    40\n",
      "10 2             idx instr  val1  val2\n",
      "2000-01-10    2     C    29     1\n",
      "10 3             idx instr  val1  val2\n",
      "2000-01-10    3     D    95    28\n",
      "10 4             idx instr  val1  val2\n",
      "2000-01-10    4     E    78    12\n",
      "11             idx instr  val1  val2\n",
      "2000-01-11    0     A    68    23\n",
      "2000-01-11    1     B    59     2\n",
      "2000-01-11    2     C    29     6\n",
      "2000-01-11    3     D    64    30\n",
      "2000-01-11    4     E    59     9\n",
      "11 0             idx instr  val1  val2\n",
      "2000-01-11    0     A    68    23\n",
      "11 1             idx instr  val1  val2\n",
      "2000-01-11    1     B    59     2\n",
      "11 2             idx instr  val1  val2\n",
      "2000-01-11    2     C    29     6\n",
      "11 3             idx instr  val1  val2\n",
      "2000-01-11    3     D    64    30\n",
      "11 4             idx instr  val1  val2\n",
      "2000-01-11    4     E    59     9\n",
      "12             idx instr  val1  val2\n",
      "2000-01-12    0     A    55     5\n",
      "2000-01-12    1     B    91    81\n",
      "2000-01-12    2     C    45    18\n",
      "2000-01-12    3     D    42    38\n",
      "2000-01-12    4     E    48    17\n",
      "12 0             idx instr  val1  val2\n",
      "2000-01-12    0     A    55     5\n",
      "12 1             idx instr  val1  val2\n",
      "2000-01-12    1     B    91    81\n",
      "12 2             idx instr  val1  val2\n",
      "2000-01-12    2     C    45    18\n",
      "12 3             idx instr  val1  val2\n",
      "2000-01-12    3     D    42    38\n",
      "12 4             idx instr  val1  val2\n",
      "2000-01-12    4     E    48    17\n",
      "13             idx instr  val1  val2\n",
      "2000-01-13    0     A    16    86\n",
      "2000-01-13    1     B    98    32\n",
      "2000-01-13    2     C    79    57\n",
      "2000-01-13    3     D    44    38\n",
      "2000-01-13    4     E    50    70\n",
      "13 0             idx instr  val1  val2\n",
      "2000-01-13    0     A    16    86\n",
      "13 1             idx instr  val1  val2\n",
      "2000-01-13    1     B    98    32\n",
      "13 2             idx instr  val1  val2\n",
      "2000-01-13    2     C    79    57\n",
      "13 3             idx instr  val1  val2\n",
      "2000-01-13    3     D    44    38\n",
      "13 4             idx instr  val1  val2\n",
      "2000-01-13    4     E    50    70\n",
      "14             idx instr  val1  val2\n",
      "2000-01-14    0     A    28    95\n",
      "2000-01-14    1     B    27    37\n",
      "2000-01-14    2     C    62    83\n",
      "2000-01-14    3     D    43    98\n",
      "2000-01-14    4     E    66    34\n",
      "14 0             idx instr  val1  val2\n",
      "2000-01-14    0     A    28    95\n",
      "14 1             idx instr  val1  val2\n",
      "2000-01-14    1     B    27    37\n",
      "14 2             idx instr  val1  val2\n",
      "2000-01-14    2     C    62    83\n",
      "14 3             idx instr  val1  val2\n",
      "2000-01-14    3     D    43    98\n",
      "14 4             idx instr  val1  val2\n",
      "2000-01-14    4     E    66    34\n",
      "15             idx instr  val1  val2\n",
      "2000-01-15    0     A    85    62\n",
      "2000-01-15    1     B    69    66\n",
      "2000-01-15    2     C    15    91\n",
      "2000-01-15    3     D    37    53\n",
      "2000-01-15    4     E     3    26\n",
      "15 0             idx instr  val1  val2\n",
      "2000-01-15    0     A    85    62\n",
      "15 1             idx instr  val1  val2\n",
      "2000-01-15    1     B    69    66\n",
      "15 2             idx instr  val1  val2\n",
      "2000-01-15    2     C    15    91\n",
      "15 3             idx instr  val1  val2\n",
      "2000-01-15    3     D    37    53\n",
      "15 4             idx instr  val1  val2\n",
      "2000-01-15    4     E     3    26\n"
     ]
    }
   ],
   "source": [
    "# We could scan manually and create the dirs manually if we don't want to add\n",
    "# add a new dir.\n",
    "base = \".\"\n",
    "dir_name =  os.path.join(base, \"parquet_dataset_partitioned2\")\n",
    "os.system(\"rm -rf %s\" % dir_name)\n",
    "\n",
    "grouped = df.groupby(lambda x: x.day)\n",
    "for day, df_tmp in grouped:\n",
    "    print(day, df_tmp)\n",
    "    grouped2 = df_tmp.groupby(\"idx\")\n",
    "    for id_, df_tmp2 in grouped2:\n",
    "        print(day, id_, df_tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4111d",
   "metadata": {},
   "source": [
    "## Partition manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0b33d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:57:11.260871Z",
     "start_time": "2021-06-15T00:57:11.235982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((year == 2009) and (month == 11)) and (day == 3))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Neither field_names nor schema was passed; cannot infer field_names",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-0a0aa4b5edb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/2009/11/3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpartitioning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/venv/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.DirectoryPartitioning.discover\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Neither field_names nor schema was passed; cannot infer field_names"
     ]
    }
   ],
   "source": [
    "from pyarrow.dataset import DirectoryPartitioning\n",
    "\n",
    "partitioning = DirectoryPartitioning(pa.schema([(\"year\", pa.int16()), (\"month\", pa.int8()), (\"day\", pa.int8())]))\n",
    "print(partitioning.parse(\"/2009/11/3\"))\n",
    "\n",
    "#partitioning.discover()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b82e0",
   "metadata": {},
   "source": [
    "## Read subset of columns for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "148be7f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T22:39:51.086061Z",
     "start_time": "2021-06-14T22:39:51.082626Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to merge PQ files\n",
    "\n",
    "# We can filter by year, month, stock and then all save in the same dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fc382c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:15:25.318533Z",
     "start_time": "2021-06-15T00:15:25.312120Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-85-fa88cdbe1cc4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-fa88cdbe1cc4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    partitioning =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "partitioning = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ef75c40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:17:55.751275Z",
     "start_time": "2021-06-15T00:17:55.740200Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-2830e85e5da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'schema'"
     ]
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d1189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.11.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
